{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    'раз два три четыре пять шесть семь',\n",
    "    'раз два пять восемь'\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'раз': 1,\n",
       " 'два': 2,\n",
       " 'пять': 3,\n",
       " 'три': 4,\n",
       " 'четыре': 5,\n",
       " 'шесть': 6,\n",
       " 'семь': 7,\n",
       " 'восемь': 8,\n",
       " 'NULL': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['NULL'] = 0\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = dict()\n",
    "\n",
    "for w, idx in tokenizer.word_index.items():\n",
    "    if embeddings.get(idx) is None:\n",
    "        embeddings[idx] = np.random.normal(size=(8,)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_embedding = np.array([embeddings[i] for i in range(len(embeddings))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_generator(text, le, ri):\n",
    "    \"\"\"\n",
    "    text: <np.array> [n_words x embed_size]\n",
    "    le: <int>: left window\n",
    "    ri: <int>: right window\n",
    "    \"\"\"\n",
    "    \n",
    "    # `NULL` SIDE-PADDING\n",
    "    # word_index['NULL'] = 0\n",
    "        \n",
    "    text = [0] * le + text + [0] * ri \n",
    "    \n",
    "    # STREAMING BATCHES\n",
    "    # AS (center_word_idx, context_word_idx) PAIRS \n",
    "    \n",
    "    for i in range(le, len(text)-ri):\n",
    "        yield (text[i], tuple(text[i-le:i] + text[i+1:i+1+ri]))\n",
    "        \n",
    "        \n",
    "\n",
    "def batch_generator(data, tokenizer, embeddings, window_size=(1, 1)):\n",
    "    for text in tokenizer.texts_to_sequences_generator(data):\n",
    "        # text = np.array([embeddings[w_idx] for w_idx in text])\n",
    "        \n",
    "        yield from window_generator(text, *window_size)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 4, 5, 3, 6, 7], [1, 2, 3, 8]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, (0, 2))\n",
      "(2, (1, 4))\n",
      "(4, (2, 5))\n",
      "(5, (4, 3))\n",
      "(3, (5, 6))\n",
      "(6, (3, 7))\n",
      "(7, (6, 0))\n",
      "(1, (0, 2))\n",
      "(2, (1, 3))\n",
      "(3, (2, 8))\n",
      "(8, (3, 0))\n"
     ]
    }
   ],
   "source": [
    "for x in batch_generator(data, tokenizer, embeddings, window_size=(1, 1)): print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "tf_sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window_left + window_right\n",
    "tf_vocab_size = 9\n",
    "tf_fitting_embed_size = 8\n",
    "tf_batch_size = 1\n",
    "tf_window_size = 2\n",
    "tf_rnn_state_size = 16\n",
    "tf_embedding_dense_size = 32\n",
    "tf_pre_embedding = tf.constant(pre_embedding, dtype=tf.float32)\n",
    "\n",
    "tf_input_context = tf.placeholder(dtype=tf.int32, shape=(tf_batch_size, tf_window_size))\n",
    "tf_input_labels = tf.placeholder(dtype=tf.int32, shape=(tf_batch_size,))\n",
    "\n",
    "tf_fitting_embedding = tf.Variable(tf.truncated_normal(shape=(tf_vocab_size, tf_fitting_embed_size), stddev=0.1))\n",
    "tf_W_out = tf.Variable(tf.truncated_normal(shape=(tf_rnn_state_size * 2 + tf_fitting_embed_size, tf_vocab_size), stddev=0.1))\n",
    "tf_b_out = tf.Variable(tf.zeros(shape=(tf_vocab_size,)))\n",
    "\n",
    "\n",
    "# EMBEDDING TENSOR [batch_size x window_size x pre_embed_size]\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    tf_context_pre_embed = tf.nn.embedding_lookup(tf_pre_embedding, tf_input_context)\n",
    "\n",
    "tf_rnn_cell_fw = tf.nn.rnn_cell.LSTMCell(16)\n",
    "tf_rnn_cell_bw = tf.nn.rnn_cell.LSTMCell(16)\n",
    "tf_rnn_state = tf_rnn_cell.zero_state(tf_batch_size, dtype=tf.float32)\n",
    "\n",
    "tf_rnn_outputs, tf_rnn_states = tf.nn.bidirectional_dynamic_rnn(\n",
    "    dtype=tf.float32,\n",
    "    cell_fw=tf_rnn_cell_fw,\n",
    "    cell_bw=tf_rnn_cell_bw,\n",
    "    inputs=tf_context_pre_embed\n",
    ")\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    tf_context_fitting_embed = tf.nn.embedding_lookup(tf_fitting_embedding, tf_input_labels)\n",
    "\n",
    "# CONCAT FW AND BW HIDDEN STATES AND FITTING EMBED OF TARGETS [batch_size x HIDDEN_STATE_SIZE * 2 + FITTING_EMBED_SIZE]\n",
    "\n",
    "tf_final_state = tf.concat(\n",
    "    [tf_rnn_states[0].c, tf_rnn_states[1].c, tf_context_fitting_embed],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "tf_logits = tf.matmul(tf_final_state, tf_W_out) + tf_b_out\n",
    "\n",
    "tf_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    labels=tf_input_labels,\n",
    "    logits=tf_logits\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_init_op = tf.global_variables_initializer()\n",
    "tf_sess = tf.Session()\n",
    "tf_sess.run(tf_init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = tf_sess.run(\n",
    "        tf_final_state,\n",
    "        {tf_input_context: np.array([[0, 2]]), tf_input_labels: np.array([1])}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 40)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05075238, -0.2744412 , -0.23570031, -0.01703531, -0.00418064,\n",
       "         0.34944135,  0.30708185, -0.15840204,  0.632811  , -0.20224315,\n",
       "         0.20672935, -0.3125187 ,  0.16155767,  0.38695666, -0.1943923 ,\n",
       "         0.20426655]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat(\n",
    "    [tf.constant(np.array([[1]])), tf.constant(np.array([[2]]))], 1\n",
    ").eval(session=tf_sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
